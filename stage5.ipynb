{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5: DeZero advanced challenge\n",
    "\n",
    "DeZero已经具备了开发神经网络的基本功能，这一阶段将增加一些额外功能，让DeZero更加完善。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import optimizers, DataLoader, test_mode\n",
    "from dezero.models import MLP\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 52: Support GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CuPy拥有与NumPy相似的接口，很容易直接进行迁移。\n",
    "\n",
    "为了让DeZero支持GPU，要能获取当前数组所属的模块，且要让DeZero能够在NumPy和CuPy之间切换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "# numpy -> cupy\n",
    "n = np.array([1, 2, 3])\n",
    "c = cp.array(n)\n",
    "assert type(c) == cp.ndarray\n",
    "\n",
    "# cupy -> numpy\n",
    "c = cp.array([1, 2, 3])\n",
    "n = cp.asnumpy(c)\n",
    "assert type(n) == np.ndarray\n",
    "\n",
    "# 获取数组模块\n",
    "x = np.array([1, 2, 3])\n",
    "xp = cp.get_array_module(x)\n",
    "assert xp == np\n",
    "\n",
    "x = cp.array([1, 2, 3])\n",
    "xp = cp.get_array_module(x)\n",
    "assert xp == cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.9050, time: 14.1970[sec]\n",
      "epoch: 2, loss: 1.2751, time: 6.1311[sec]\n",
      "epoch: 3, loss: 0.9201, time: 6.5514[sec]\n",
      "epoch: 4, loss: 0.7378, time: 5.6780[sec]\n",
      "epoch: 5, loss: 0.6343, time: 5.6873[sec]\n"
     ]
    }
   ],
   "source": [
    "# 超参数设置\n",
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "\n",
    "# 数据集\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "\n",
    "# 模型\n",
    "model = MLP((1000, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    model.to_gpu()\n",
    "\n",
    "# 训练\n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    print('epoch: {}, loss: {:.4f}, time: {:.4f}[sec]'.format(\n",
    "        epoch + 1, sum_loss / len(train_set), elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 53: Model saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeZero的参数为Parameter类的实例，而Parameter的数据则作为ndarray实例保存在变量data中。使用NumPy的函数来进行保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([1, 2, 3])\n",
    "x2 = np.array([4, 5, 6])\n",
    "data = {'x1': x1, 'x2': x2}\n",
    "\n",
    "np.savez('test.npz', **data)\n",
    "\n",
    "arrays = np.load('test.npz')\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer的层次结构是一个嵌套的结构，为了取出参数，可以将其“展平”，实际是递归地取出参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.9778\n",
      "epoch: 2, loss: 0.8133\n",
      "epoch: 3, loss: 0.7077\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 3\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "model = MLP((100, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "if os.path.exists('my_mlp.npz'):\n",
    "    model.load_weights('my_mlp.npz')\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "    \n",
    "    print('epoch: {}, loss: {:.4f}'.format(\n",
    "        epoch + 1, sum_loss / len(train_set)))\n",
    "    \n",
    "model.save_weights('my_mlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 54: Dropout and test mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout通过随机删除/禁用神经元来解决模型表现了太强而引起的过拟合问题，达到与集成学习相同的效果。\n",
    "\n",
    "在测试时，模型使用所有的神经元，但需要进行弱化输出！因为训练时只有一定量的神经元存活，乘以弱化比例使得缩放尺度上保持一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.6\n",
    "x = np.ones(10)\n",
    "\n",
    "# train\n",
    "mask = np.random.rand(10) > dropout_rate  # mask掉部分神经元\n",
    "y = x * mask\n",
    "print(y)\n",
    "\n",
    "# test\n",
    "scale = 1 - dropout_rate\n",
    "y = x * scale  # 保持相同的缩放尺度\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大部分dl框架都使用Inverted Dropout，在训练时进行缩放处理，测试时就无需进行额外处理。这样还能支持动态的dropout_ratio，Direct Dropout如果动态改变会导致测试时行为不一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.  2.5 0.  2.5 2.5 2.5 2.5 2.5]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.6\n",
    "x = np.ones(10)\n",
    "\n",
    "# train\n",
    "scale = 1- dropout_rate\n",
    "mask = np.random.rand(10) > dropout_rate  # mask掉部分神经元\n",
    "y = x * mask / scale\n",
    "print(y)\n",
    "\n",
    "# test\n",
    "y = x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用Dropout时需要区分训练阶段和测试阶段，需要进行相应地设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "variable([0. 2. 2. 0. 2.])\n",
      "variable([1. 1. 1. 1. 1.])\n"
     ]
    }
   ],
   "source": [
    "x = np.ones(5)\n",
    "print(x)\n",
    "\n",
    "y = F.dropout(x)\n",
    "print(y)\n",
    "\n",
    "with test_mode():\n",
    "    y = F.dropout(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 55: CNN Ⅰ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN中出现了新的层，卷积层(Convolution layer)和池化层(pooling layer)。\n",
    "\n",
    "卷积层执行卷积运算，相当于对图像进行过滤操作：\n",
    "<center>\n",
    "<table>\n",
    "<img src=\"./res/conv.png\" width=\"400\"/>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "上图卷积核在水平和垂直两个方向上移动，称为二维卷积层Conv2d，当然也有一维卷积层Conv1d和三维卷积层Conv3d。\n",
    "\n",
    "卷积运算后回缩小图像，为了保持图像大小，可以在卷积运算后进行填充(padding)操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "def get_conv_output_size(input_size, kernel_size, stride, pad):\n",
    "    return (input_size + pad * 2 - kernel_size) // stride + 1\n",
    "\n",
    "H, W = 4, 4  # Input size\n",
    "KH, KW = 3, 3  # Kernel size\n",
    "SH, SW = 1, 1  # Stride\n",
    "PH, PW = 1, 1  # Padding\n",
    "\n",
    "OH = get_conv_output_size(H, KH, SH, PH)\n",
    "OW = get_conv_output_size(W, KW, SW, PW)\n",
    "print(OH, OW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 56: CNN Ⅱ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像除了垂直和水平方向，还在通道方向上排列，DeZero要能处理这种三阶张量。\n",
    "<center>\n",
    "<table>\n",
    "<img src=\"./res/conv2.png\" width=\"400\"/>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "池化处理是缩小垂直和水平方向空间的操作，包括最大池化、平均池化等，一般池化窗口大小和步幅设置为相同的值。\n",
    "1. 没有学习参数\n",
    "2. 通道数量不发生变化\n",
    "3. 对微小的位置变化具有鲁棒性\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
