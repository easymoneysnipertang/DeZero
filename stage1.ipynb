{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Automatically compute derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Variables as boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将变量比作\"箱子\"\n",
    "- \"箱子\"和数据是不同的东两\n",
    "- \"箱子\"里可以存放数据(=赋值)\n",
    "- 朝\"箱子\"里看一看就能知道数据是什么(=引用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, data):\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "data = np.array(1.0)\n",
    "x = Variable(data)\n",
    "print(x.data) # 1.0\n",
    "\n",
    "x.data = np.array(2.0)\n",
    "print(x.data) # 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Function to create a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数是定义一个变量与另一个变量之间的对应关系的规则\n",
    "- 在 Function 类中实现的方法，其输入应为 Variable 实例，输出应为Variable 实例\n",
    "- Variable 实例的实际数据存在于实例变量 data 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数的基类\n",
    "class Function:\n",
    "    def __call__(self, input):\n",
    "        x = input.data\n",
    "        y = self.forward(x)\n",
    "        output = Variable(y)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square(Function):\n",
    "    def forward(self, x):\n",
    "        return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Variable'>\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "x = Variable(np.array(10))\n",
    "f = Square()\n",
    "y = f(x)\n",
    "print(type(y)) # <class '__main__.Variable'>\n",
    "print(y.data) # 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Connecting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数连续调用，可以视作一个大函数(复合函数)  \n",
    "计算图：  \n",
    "x -> A -> a -> B -> b -> C -> y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp(Function):\n",
    "    def forward(self, x):\n",
    "        return np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.648721270700128\n"
     ]
    }
   ],
   "source": [
    "A = Square()\n",
    "B = Exp()\n",
    "C = Square()\n",
    "\n",
    "x = Variable(np.array(0.5))\n",
    "a = A(x)\n",
    "b = B(a)\n",
    "y = C(b)\n",
    "print(y.data) # 1.648721270700128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Numerical Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{df}{dx} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h} $$\n",
    "\n",
    "将h设为一个很小的数，计算导数的近似值(数值微分)  \n",
    "中心差分误差更小：\n",
    "$$ \\frac{df}{dx} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x-h)}{2h} $$\n",
    "\n",
    "数值微分由于\"精度丢失\"，结果始终容易包含误差，更严重的是计算成本高昂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x, eps=1e-4):\n",
    "    x0 = Variable(x.data - eps)\n",
    "    x1 = Variable(x.data + eps)\n",
    "    y0 = f(x0)\n",
    "    y1 = f(x1)\n",
    "    return (y1.data - y0.data) / (2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000000000004\n"
     ]
    }
   ],
   "source": [
    "f = Square()\n",
    "x = Variable(np.array(2.0))\n",
    "dy = numerical_diff(f, x)\n",
    "print(dy) # 4.000000000004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2974426293330694\n"
     ]
    }
   ],
   "source": [
    "# 复合函数\n",
    "def f(x):\n",
    "    A = Square()\n",
    "    B = Exp()\n",
    "    C = Square()\n",
    "    return C(B(A(x)))\n",
    "\n",
    "x = Variable(np.array(0.5))\n",
    "dy = numerical_diff(f, x)\n",
    "print(dy) # 3.2974426293330694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Theory of Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "链式法则:\n",
    "$\\frac{dy}{dx}=\\frac{dy}{dy} \\frac{dy}{db} \\frac{db}{da} \\frac{da}{dx}$\n",
    "\n",
    "y对各变量的导数可以通过计算图的反向传播得到 (沿着输出到输入的方向，传播一次即可得到)\n",
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"res/计算图.png\" width=\"400\"/></td>\n",
    "    <td><img src=\"res/计算图2.png\" width=\"400\"/></td>\n",
    "  </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "如上图所示，正向传播与反向传播存在明确的对应关系，我们可以认为变量有普通值和导数值，函数有普通计算(正向传播)和求导计算(反向传播)\n",
    "\n",
    "反向传播是需要用到正向传播中使用的数据，因此需要先进行正向传播，再进行反向传播，并且存储各个函数输入的变量值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Backpropagation by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.grad = None  # 增加grad保存梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function:\n",
    "    def __call__(self, input):\n",
    "        x = input.data\n",
    "        y = self.forward(x)\n",
    "        output = Variable(y)\n",
    "        self.input = input  # 保存输入（input保存到了实例变量中）\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward(self, gy):  # gy是从上游传来的导数\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square(Function):\n",
    "    def forward(self, x):\n",
    "        return x ** 2\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x = self.input.data\n",
    "        gx = 2 * x * gy  # y = x^2的导数是2x\n",
    "        return gx\n",
    "\n",
    "class Exp(Function):\n",
    "    def forward(self, x):\n",
    "        return np.exp(x)\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x = self.input.data\n",
    "        gx = np.exp(x) * gy  # y = exp(x)的导数是exp(x)\n",
    "        return gx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Square()\n",
    "B = Exp()\n",
    "C = Square()\n",
    "\n",
    "x = Variable(np.array(0.5))\n",
    "a = A(x)\n",
    "b = B(a)\n",
    "y = C(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.297442541400256\n"
     ]
    }
   ],
   "source": [
    "# 反向调用backward方法\n",
    "y.grad = np.array(1.0)\n",
    "b.grad = C.backward(y.grad)\n",
    "a.grad = B.backward(b.grad)\n",
    "x.grad = A.backward(a.grad)\n",
    "print(x.grad) # 3.297442541400256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Automation of Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: From Recusion to Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Making Funcions More Useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Perfrom the test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
